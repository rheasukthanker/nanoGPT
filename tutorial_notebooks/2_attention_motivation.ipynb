{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c9e87b-d3f6-4112-aa94-e1ae71b2056b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=\n",
      "tensor([[[-2.0260, -2.0655, -1.2054],\n",
      "         [-0.9122, -1.2502,  0.8032]]])\n",
      "--\n",
      "xbow=\n",
      "tensor([[[-2.0260, -2.0655, -1.2054],\n",
      "         [-1.4691, -1.6579, -0.2011]]])\n"
     ]
    }
   ],
   "source": [
    "# Simplest way to use context is average on all the previous chars\n",
    "# This is called bow (bag of words)\n",
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 1,2,3 # batch, time, channels (vocab size)\n",
    "x = torch.randn(B,T,C) \n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "print('x=')\n",
    "print(x)\n",
    "print('--')\n",
    "print('xbow=')\n",
    "print(xbow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14c390bb-7190-46b9-86d6-a4f5c0d39c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei=\n",
      "tensor([[1.0000, 0.0000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation, faster and recommended\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "print(\"wei=\")\n",
    "print(wei)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "671261c2-b652-4cdc-a073-8b4482c5968d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei=\n",
      "tensor([[1.0000, 0.0000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "import torch.nn.functional as F\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(\"wei=\")\n",
    "print(wei)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d68f31c8-706b-41f3-af2a-97ead17c1c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Question: What are the disadvantages and advantages of bow?\n",
    "# 1. Why should all the tokens in the history be equally important?\n",
    "# 2. We may want to take a weighted combination for eg: weight closer tokens more than others?\n",
    "# 3. Consider an example of coreference resolution \"Bruno is my pet dog. He is a labrador\". \n",
    "# In this case \"He\" should resolve to \"Bruno\" or \"dog\" and these components in the history much be weighted(attended to) more than the others\n",
    "# 4. Why should the weighing be constant across batches?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5785403-8dba-41ca-921f-daac3e5bc92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
